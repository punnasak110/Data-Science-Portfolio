{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3c57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting . . .\n"
     ]
    }
   ],
   "source": [
    "print('starting . . .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caabbc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# 1. IMPORT LIBRARIES (นำเข้า PyTorch และ Tools ที่จำเป็น)\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "# 2. HYPERPARAMETERS & CONFIGURATION\n",
    "NUM_CLASSES = 72    # 72 คลาส (ตัวอักษรไทย)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "MODEL_NAME = \"resnet18\"\n",
    "IMAGE_SIZE = 128\n",
    "DATA_DIR = \"C:\\\\Users\\\\HP\\\\Downloads\\\\train(1)\\\\data-train\" # ตำแหน่งโฟลเดอร์หลัก # ตำแหน่งโฟลเดอร์หลัก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde72098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data transformations are defined successfully!\n",
      "\n",
      "--- Training Transforms (Updated) ---\n",
      "Compose(\n",
      "    <__main__.PadToSquare object at 0x000002425A9DA740>\n",
      "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.05, 0.05), scale=(0.95, 1.05), shear=[-5.0, 5.0])\n",
      "    <__main__.RandomFontStyle object at 0x000002425A9DB220>\n",
      "    RandomApply(\n",
      "    p=0.3\n",
      "    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.8))\n",
      ")\n",
      "    <__main__.AddSaltPepperNoise object at 0x000002425A9DB3A0>\n",
      "    <__main__.RandomErosionDilation object at 0x000002425A9DB400>\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      ")\n",
      "\n",
      "--- Validation/Test Transforms (Updated) ---\n",
      "Compose(\n",
      "    <__main__.PadToSquare object at 0x000002425A9DA800>\n",
      "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageFilter, ImageEnhance\n",
    "import random\n",
    "import math\n",
    "\n",
    "# --- 0. DEFINE ALL CUSTOM AUGMENTATION CLASSES ---\n",
    "# คลาสที่เพิ่มเข้ามาใหม่ 3 คลาสตามโค้ดของเพื่อน\n",
    "class AddSaltPepperNoise(object):\n",
    "    \"\"\"เพิ่ม Salt & Pepper noise\"\"\"\n",
    "    def __init__(self, amount=0.005):\n",
    "        self.amount = amount\n",
    "\n",
    "    def __call__(self, img):\n",
    "        np_img = np.array(img)\n",
    "        # ตรวจสอบว่าเป็นภาพสีหรือไม่\n",
    "        if len(np_img.shape) == 3:\n",
    "            # ทำ noise กับแต่ละ channel\n",
    "            for i in range(np_img.shape[2]):\n",
    "                channel = np_img[:, :, i]\n",
    "                num_noise = int(self.amount * channel.size)\n",
    "                # Salt\n",
    "                coords_salt = [np.random.randint(0, s - 1, num_noise // 2) for s in channel.shape]\n",
    "                channel[tuple(coords_salt)] = 255\n",
    "                # Pepper\n",
    "                coords_pepper = [np.random.randint(0, s - 1, num_noise // 2) for s in channel.shape]\n",
    "                channel[tuple(coords_pepper)] = 0\n",
    "        else: # ภาพ Grayscale\n",
    "            num_noise = int(self.amount * np_img.size)\n",
    "            # Salt\n",
    "            coords_salt = [np.random.randint(0, s - 1, num_noise // 2) for s in np_img.shape]\n",
    "            np_img[tuple(coords_salt)] = 255\n",
    "            # Pepper\n",
    "            coords_pepper = [np.random.randint(0, s - 1, num_noise // 2) for s in np_img.shape]\n",
    "            np_img[tuple(coords_pepper)] = 0\n",
    "        \n",
    "        return Image.fromarray(np_img)\n",
    "\n",
    "\n",
    "class RandomErosionDilation(object):\n",
    "    \"\"\"สุ่มทำ erosion/dilation เบา ๆ\"\"\"\n",
    "    def __init__(self, prob=0.05):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            # ต้องแปลงเป็น 'L' (Grayscale) ก่อนใช้ filter ประเภทนี้\n",
    "            img_gray = img.convert('L')\n",
    "            if random.random() < 0.5:\n",
    "                processed_gray = img_gray.filter(ImageFilter.MinFilter(3))  # erosion\n",
    "            else:\n",
    "                processed_gray = img_gray.filter(ImageFilter.MaxFilter(3))  # dilation\n",
    "            # ถ้าภาพเดิมเป็นสี ให้ merge กลับ\n",
    "            if img.mode == 'RGB':\n",
    "                # สร้างภาพสีจาก channel ที่ process แล้ว\n",
    "                return Image.merge('RGB', (processed_gray, processed_gray, processed_gray))\n",
    "            else:\n",
    "                return processed_gray\n",
    "        return img\n",
    "\n",
    "\n",
    "class PadToSquare(object):\n",
    "    \"\"\"Padding ให้เป็นจตุรัสก่อน resize\"\"\"\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        max_side = max(w, h)\n",
    "        delta_w = max_side - w\n",
    "        delta_h = max_side - h\n",
    "        padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "        # ใช้ fill=(0,0,0) สำหรับพื้นหลังสีดำ หรือ (255,255,255) สำหรับสีขาว\n",
    "        # หากภาพเป็น Grayscale ต้องใช้ fill=0 หรือ fill=255\n",
    "        fill_color = 0 if img.mode == 'L' else (0,0,0)\n",
    "        return ImageOps.expand(img, padding, fill=fill_color)\n",
    "\n",
    "# คลาสเดิมของคุณ\n",
    "class RandomFontStyle(object):\n",
    "    \"\"\"สุ่มปรับให้ตัวอักษรหนาขึ้น/เอียงเล็กน้อย (จำลอง bold / italic)\"\"\"\n",
    "    def __init__(self, prob=0.3, bold_factor=(1.0, 1.3), italic_angle=(-8, 8)):\n",
    "        self.prob = prob\n",
    "        self.bold_factor = bold_factor\n",
    "        self.italic_angle = italic_angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # (โค้ดใน __call__ เหมือนเดิม)\n",
    "        if random.random() < self.prob:\n",
    "            factor = random.uniform(*self.bold_factor)\n",
    "            enhancer = ImageEnhance.Contrast(img)\n",
    "            img = enhancer.enhance(factor)\n",
    "            angle = random.uniform(*self.italic_angle)\n",
    "            img = img.transform(\n",
    "                img.size, Image.AFFINE,\n",
    "                (1, math.tan(math.radians(angle)) / 2, 0, 0, 1, 0),\n",
    "                resample=Image.BICUBIC\n",
    "            )\n",
    "        return img\n",
    "\n",
    "\n",
    "# --- 1. DEFINE IMAGE PARAMETERS ---\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "# --- 2. DEFINE DATA TRANSFORMATIONS ---\n",
    "\n",
    "# --- A. TRAIN TRANSFORMS (ปรับแก้ให้เหมือนเพื่อน) ---\n",
    "train_transforms = transforms.Compose([\n",
    "    PadToSquare(), # เปลี่ยนมาใช้ PadToSquare เพื่อรักษาสัดส่วน\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), # Resize ทันทีหลัง Pad\n",
    "    \n",
    "    transforms.RandomRotation(10), # ลดองศาการหมุน\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0, \n",
    "        translate=(0.05, 0.05), # ลดการเลื่อน\n",
    "        scale=(0.95, 1.05),   # ลดการย่อขยาย\n",
    "        shear=5               # ลดการเฉือน\n",
    "    ),\n",
    "    \n",
    "    # เพิ่ม RandomFontStyle เข้ามา (เหมือนที่คุณมี)\n",
    "    RandomFontStyle(prob=0.3),\n",
    "    \n",
    "    # ปรับ GaussianBlur และเอา ColorJitter ออก\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.8))\n",
    "    ], p=0.3),\n",
    "    \n",
    "    # เพิ่ม Augmentation 2 ตัวใหม่ตามเพื่อน\n",
    "    AddSaltPepperNoise(amount=0.005),\n",
    "    RandomErosionDilation(prob=0.15),\n",
    "    \n",
    "    # ขั้นตอนสุดท้ายเหมือนเดิม\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# --- B. VALIDATION/TEST TRANSFORMS () ---\n",
    "val_test_transforms = transforms.Compose([\n",
    "    PadToSquare(), # เพิ่ม PadToSquare ให้เหมือน train set\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "print(\"✅ Data transformations are defined successfully!\")\n",
    "print(\"\\n--- Training Transforms (Updated) ---\")\n",
    "print(train_transforms)\n",
    "print(\"\\n--- Validation/Test Transforms (Updated) ---\")\n",
    "print(val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfe5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- เริ่มการ Training ---\n",
      "Epoch 1/10 | Train Loss: 0.1827 | Val Accuracy: 98.14%\n",
      "✅ New best model saved with accuracy: 98.14%\n",
      "Epoch 2/10 | Train Loss: 0.0756 | Val Accuracy: 98.05%\n",
      "Epoch 3/10 | Train Loss: 0.0607 | Val Accuracy: 97.60%\n",
      "Epoch 4/10 | Train Loss: 0.0539 | Val Accuracy: 98.49%\n",
      "✅ New best model saved with accuracy: 98.49%\n",
      "Epoch 5/10 | Train Loss: 0.0477 | Val Accuracy: 97.85%\n",
      "Epoch 6/10 | Train Loss: 0.0417 | Val Accuracy: 98.71%\n",
      "✅ New best model saved with accuracy: 98.71%\n",
      "Epoch 7/10 | Train Loss: 0.0428 | Val Accuracy: 98.82%\n",
      "✅ New best model saved with accuracy: 98.82%\n",
      "Epoch 8/10 | Train Loss: 0.0400 | Val Accuracy: 99.10%\n",
      "✅ New best model saved with accuracy: 99.10%\n",
      "Epoch 9/10 | Train Loss: 0.0321 | Val Accuracy: 98.62%\n",
      "Epoch 10/10 | Train Loss: 0.0364 | Val Accuracy: 98.73%\n",
      "--- Training เสร็จสมบูรณ์ โมเดลที่ดีที่สุดมี Val Accuracy: 99.10% ---\n"
     ]
    }
   ],
   "source": [
    "# (ส่วนที่ 1 และ 2 ของคุณสมมติว่าอยู่ข้างบน)\n",
    "\n",
    "# --- ส่วนที่ 3 (แก้ไข) และ 4 ---\n",
    "\n",
    "# 4. สร้าง Datasets แยกสำหรับ Train และ Validation\n",
    "# วิธีนี้จะปลอดภัยและชัดเจนกว่าการ Split ทีหลัง\n",
    "train_dataset_full = datasets.ImageFolder(\n",
    "    DATA_DIR, \n",
    "    transform=train_transforms # ใช้ Train Transforms สำหรับข้อมูลทั้งหมดก่อน\n",
    ")\n",
    "val_dataset_full = datasets.ImageFolder(\n",
    "    DATA_DIR, \n",
    "    transform=val_test_transforms # ใช้ Val Transforms สำหรับข้อมูลทั้งหมดก่อน\n",
    ")\n",
    "\n",
    "\n",
    "# 5. SPLIT DATA (แบ่งข้อมูลเป็น Train และ Validation: 80% : 20%)\n",
    "TRAIN_RATIO = 0.8\n",
    "train_size = int(TRAIN_RATIO * len(train_dataset_full))\n",
    "val_size = len(train_dataset_full) - train_size\n",
    "\n",
    "# ทำการ Split โดยใช้ indices ที่ได้จากการสุ่ม\n",
    "indices = list(range(len(train_dataset_full)))\n",
    "np.random.shuffle(indices) # สลับลำดับ indices\n",
    "train_indices, val_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# สร้าง Subsets จาก indices ที่แบ่งไว้\n",
    "train_dataset = torch.utils.data.Subset(train_dataset_full, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset_full, val_indices)\n",
    "\n",
    "\n",
    "# 6. CREATE DATALOADERS\n",
    "# แนะนำให้เริ่มที่ num_workers=0 ก่อนเพื่อความเสถียร\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=0 # <--- แนะนำให้เริ่มที่ 0\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=0 # <--- แนะนำให้เริ่มที่ 0\n",
    ")\n",
    "\n",
    "# --- ส่วนที่ 4 (เหมือนเดิม) ---\n",
    "# ... (โค้ดสร้าง model, criterion, optimizer) ...\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- ส่วนที่ 5 (แก้ไขเรื่องการ Save โมเดล) ---\n",
    "print(\"--- เริ่มการ Training ---\")\n",
    "\n",
    "best_val_accuracy = 0.0 # <--- เพิ่ม: ตัวแปรสำหรับเก็บ Accuracy ที่ดีที่สุด\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- A. TRAINING PHASE ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # ... (โค้ด Train เหมือนเดิม) ...\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss_train = running_loss / len(train_dataset)\n",
    "    \n",
    "    # --- B. VALIDATION PHASE ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # ... (โค้ด Validation เหมือนเดิม) ...\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy_val = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {epoch_loss_train:.4f} | Val Accuracy: {accuracy_val:.2f}%')\n",
    "    \n",
    "    # --- C. SAVE BEST MODEL LOGIC (เพิ่มเข้ามา) ---\n",
    "    if accuracy_val > best_val_accuracy:\n",
    "        best_val_accuracy = accuracy_val\n",
    "        # บันทึกเฉพาะเมื่อ Val Accuracy ดีขึ้น\n",
    "        torch.save(model.state_dict(), f'{MODEL_NAME}_best_model.pth')\n",
    "        print(f\"✅ New best model saved with accuracy: {best_val_accuracy:.2f}%\")\n",
    "\n",
    "print(f\"--- Training เสร็จสมบูรณ์ โมเดลที่ดีที่สุดมี Val Accuracy: {best_val_accuracy:.2f}% ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
